{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCGYbZydm4NobAN8NZHpzS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/hopfield_boltzmann/blob/main/section_2/02_hopfield_network_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pythonのクラスでホップフィールドネットワークを実装する\n",
        "ホップフィールドネットワークのコードがどのように動作するのか、さらに詳しく解説します。"
      ],
      "metadata": {
        "id": "D1ewu_ttnVop"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ホップフィールドネットワークの全体コード\n",
        "以降、クラス`HopfieldNetwork`を構成する各メソッドを解説します。\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "class HopfieldNetwork:\n",
        "    def __init__(self, num_neurons):\n",
        "        self.num_neurons = num_neurons\n",
        "        self.weights = np.zeros((num_neurons, num_neurons))\n",
        "\n",
        "    def train(self, patterns):\n",
        "        for p in patterns:\n",
        "            p = p.reshape(self.num_neurons, 1)  # パターンを列ベクトルに変換\n",
        "            self.weights += np.dot(p, p.T)      # 外積で重み行列を更新\n",
        "        np.fill_diagonal(self.weights, 0)       # 対角要素を0に設定\n",
        "\n",
        "    def recall(self, pattern, steps=5):\n",
        "        result = pattern.copy()\n",
        "        for _ in range(steps):\n",
        "            result = np.sign(np.dot(self.weights, result))\n",
        "        return result\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 1. `__init__` メソッド（初期化）\n",
        "\n",
        "```python\n",
        "def __init__(self, num_neurons):\n",
        "    self.num_neurons = num_neurons\n",
        "    self.weights = np.zeros((num_neurons, num_neurons))\n",
        "```\n",
        "\n",
        "### 解説\n",
        "- **役割**:\n",
        "  - ネットワークの初期化を行います。\n",
        "  - ニューロンの数と重み行列（weights）を初期化します。\n",
        "\n",
        "- **パラメータ**:\n",
        "  - `num_neurons`: ニューロンの数（ネットワークに記憶させるパターンの要素数に対応）。\n",
        "\n",
        "- **動作**:\n",
        "  - `self.num_neurons`: ネットワークのニューロン数を設定。\n",
        "  - `self.weights`: **重み行列**（`num_neurons x num_neurons` の2次元配列）をゼロ行列で初期化。\n",
        "    - この行列は、ニューロン同士の結合の強さを表します。\n",
        "    - 初期状態では、すべての結合がゼロ（つまり影響を与えない）になっています。\n",
        "\n",
        "---\n",
        "\n",
        "## 2. `train` メソッド（学習）\n",
        "\n",
        "```python\n",
        "def train(self, patterns):\n",
        "    for p in patterns:\n",
        "        p = p.reshape(self.num_neurons, 1)  # パターンを列ベクトルに変換\n",
        "        self.weights += np.dot(p, p.T)      # 外積で重み行列を更新\n",
        "    np.fill_diagonal(self.weights, 0)       # 対角要素を0に設定\n",
        "```\n",
        "\n",
        "### 解説\n",
        "- **役割**:\n",
        "  - 複数のパターンをホップフィールドネットワークに**学習**させます。\n",
        "  - 各パターンの外積（※補足で解説）を用いて、重み行列を更新します（**Hebbian学習**）。\n",
        "\n",
        "- **パラメータ**:\n",
        "  - `patterns`: 学習させたいパターンのリスト（各パターンは1次元の配列）。\n",
        "\n",
        "- **動作の流れ**:\n",
        "  1. **パターンを列ベクトルに変換**:\n",
        "     ```python\n",
        "     p = p.reshape(self.num_neurons, 1)\n",
        "     ```\n",
        "     - ここでは、パターン `p` を縦に並んだ**列ベクトル**に変換します。\n",
        "     - 例: `[1, -1, 1]` → `[[1], [-1], [1]]`\n",
        "\n",
        "  2. **重み行列の更新**:\n",
        "     ```python\n",
        "     self.weights += np.dot(p, p.T)\n",
        "     ```\n",
        "     - `np.dot(p, p.T)` は **外積** （※補足で解説）を計算します。\n",
        "     - 外積を使って、ニューロン同士の結合の強さ（重み）を決定します。\n",
        "     - 外積の例:\n",
        "       - パターン `p = [[1], [-1], [1]]` の場合、`np.dot(p, p.T)` の結果は次のようになります：\n",
        "         ```\n",
        "         [[ 1, -1,  1],\n",
        "          [-1,  1, -1],\n",
        "          [ 1, -1,  1]]\n",
        "         ```\n",
        "     - 各パターンについて、この重み行列を累積していきます。\n",
        "\n",
        "  3. **対角要素をゼロに設定**:\n",
        "     ```python\n",
        "     np.fill_diagonal(self.weights, 0)\n",
        "     ```\n",
        "     - 重み行列の **対角要素**（自己結合）はゼロに設定します。\n",
        "     - これにより、各ニューロンが **自分自身に影響を与えない** ようにします。\n",
        "\n",
        "---\n",
        "\n",
        "## 3. `recall` メソッド（パターンの再現）\n",
        "\n",
        "```python\n",
        "def recall(self, pattern, steps=5):\n",
        "    result = pattern.copy()\n",
        "    for _ in range(steps):\n",
        "        result = np.sign(np.dot(self.weights, result))\n",
        "    return result\n",
        "```\n",
        "\n",
        "### 解説\n",
        "- **役割**:\n",
        "  - **ノイズの入ったパターン**を入力し、ホップフィールドネットワークが学習したパターンを**再現**（復元）する。\n",
        "  - 反復的に重み行列を用いて入力を修正し、学習済みパターンに収束させます。\n",
        "\n",
        "- **パラメータ**:\n",
        "  - `pattern`: 再現したいパターン（入力として与える1次元配列）。\n",
        "  - `steps`: 再現のために行う**更新の回数**（デフォルトは5回）。\n",
        "\n",
        "- **動作の流れ**:\n",
        "  1. **入力パターンのコピーを作成**:\n",
        "     ```python\n",
        "     result = pattern.copy()\n",
        "     ```\n",
        "     - 元の入力パターンを変更しないように、コピーを作成します。\n",
        "\n",
        "  2. **重み行列を用いた更新ループ**:\n",
        "     ```python\n",
        "     for _ in range(steps):\n",
        "         result = np.sign(np.dot(self.weights, result))\n",
        "     ```\n",
        "     - 重み行列と入力パターンの **内積** を計算し、その結果を符号関数（`np.sign`）を使って -1 または 1 に変換します。\n",
        "     - これを `steps` 回繰り返して、**パターンが安定するまで更新** します。\n",
        "       - 正の値 → 1\n",
        "       - 負の値 → -1\n",
        "\n",
        "  3. **修正されたパターンを返す**:\n",
        "     - 更新が終了したら、修正されたパターンを返します。\n",
        "     - このパターンは、ネットワークが学習したパターンに収束していることが期待されます。\n",
        "\n",
        "---\n",
        "\n",
        "### 具体例での動作の理解\n",
        "\n",
        "- **学習したパターン**: `pattern1 = [1, -1, 1, -1, 1, -1, 1, -1, 1]`\n",
        "- **ノイズの入った入力**: `noisy_pattern = [1, 1, 1, -1, 1, -1, 1, -1, -1]`\n",
        "- **再現結果**:\n",
        "  - ノイズの入った `noisy_pattern` を `recall` メソッドに入力すると、ホップフィールドネットワークは学習済みの `pattern1` に収束します。\n",
        "\n",
        "---\n",
        "\n",
        "### まとめ\n",
        "- `train` メソッドでパターンを記憶し、重み行列を構築します。\n",
        "- `recall` メソッドで、ノイズの入った入力を修正し、学習済みのパターンに収束させます。\n",
        "- ホップフィールドネットワークは、**ノイズ除去** や **パターンの連想記憶** に適しており、シンプルな構造で強力な連想メモリを実現できます。\n",
        "\n",
        "このクラスの基本的な仕組みを理解することで、ホップフィールドネットワークを使った応用タスク（画像のノイズ除去、パターンの復元など）に発展させることができます。"
      ],
      "metadata": {
        "id": "lrb39E2IOpAq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## （補足）「外積」についての解説\n",
        "\n",
        "ホップフィールドネットワークの **`train` メソッド** の中で使用されている「外積」 (`np.dot(p, p.T)`) について、詳しく解説します。\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **外積とは？**\n",
        "外積（Outer Product）は、**ベクトルとベクトルから行列を生成する操作** のことを指します。具体的には、**縦ベクトル** と **横ベクトル** を掛け合わせることで、**行列** を作ります。\n",
        "\n",
        "- **内積**（Dot Product）はスカラー（数値）を返すのに対して、\n",
        "- **外積** は行列を返します。\n",
        "\n",
        "#### 数学的な定義\n",
        "2つのベクトル $\\mathbf{a}$ と $\\mathbf{b}$ の外積は、次のように表されます：\n",
        "$$\n",
        "\\mathbf{a} \\otimes \\mathbf{b} = \\mathbf{a} \\cdot \\mathbf{b}^T\n",
        "$$\n",
        "- ここで、$\\mathbf{a}$ は **縦ベクトル**、$\\mathbf{b}^T$ は **横ベクトル** にしたものです。\n",
        "- 結果として、**行列** が得られます。\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **ホップフィールドネットワークにおける外積の使い方**\n",
        "ホップフィールドネットワークでは、**パターンの記憶** に外積を利用しています。この操作により、各ニューロン間の結合強度（重み行列）が決まります。\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **具体例で理解する**\n",
        "\n",
        "#### 例\n",
        "ここでは、シンプルなパターン $p$ を使って、外積がどのように計算されるかを示します。\n",
        "\n",
        "- **パターン** $p = [1, -1, 1]$\n",
        "- **列ベクトル** として表すと：\n",
        "\n",
        "$$\n",
        "p = \\begin{bmatrix} 1 \\\\ -1 \\\\ 1 \\end{bmatrix}\n",
        "$$\n",
        "\n",
        "##### 外積の計算\n",
        "$$\n",
        "\\text{外積: } p \\otimes p^T = \\begin{bmatrix} 1 \\\\ -1 \\\\ 1 \\end{bmatrix} \\times \\begin{bmatrix} 1 & -1 & 1 \\end{bmatrix}\n",
        "$$\n",
        "\n",
        "- 計算の結果は次の **行列** になります：\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "1 \\times 1 & 1 \\times -1 & 1 \\times 1 \\\\\n",
        "-1 \\times 1 & -1 \\times -1 & -1 \\times 1 \\\\\n",
        "1 \\times 1 & 1 \\times -1 & 1 \\times 1\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "1 & -1 & 1 \\\\\n",
        "-1 & 1 & -1 \\\\\n",
        "1 & -1 & 1\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **ホップフィールドネットワークでの利用**\n",
        "ホップフィールドネットワークでは、各パターンについてこの外積を計算し、それを **重み行列に累積** していきます。これにより、複数のパターンを同時に記憶することが可能になります。\n",
        "\n",
        "#### 重み行列の更新\n",
        "```python\n",
        "self.weights += np.dot(p, p.T)\n",
        "```\n",
        "\n",
        "- ここで、`p` は列ベクトル（縦ベクトル）に変換されたパターンです。\n",
        "- `np.dot(p, p.T)` を使って **外積** を計算し、重み行列 `self.weights` に加算します。\n",
        "- この処理を **すべてのパターン** について繰り返すことで、重み行列が更新されます。\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **重み行列が学習に与える影響**\n",
        "重み行列は、ホップフィールドネットワークがパターンを記憶し、再現するための「記憶装置」として機能します。\n",
        "\n",
        "- ノイズの入ったパターンを入力した際、重み行列は入力パターンを元に、記憶しているパターンに**収束**させる力を発揮します。\n",
        "- これは、重み行列が各ニューロン間の結合を適切に調整しているためです。\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **まとめ**\n",
        "- **外積** は、ホップフィールドネットワークにおいて、パターンを記憶するための重み行列を構築するために利用されています。\n",
        "- **重み行列** の各要素は、ニューロン同士の結合の強さを表し、ネットワークが入力パターンを正しく再現するために重要な役割を果たします。\n",
        "- **外積** を利用することで、パターン同士の相関関係を重み行列に反映させ、パターンの連想記憶を実現しています。\n",
        "\n",
        "---\n",
        "\n",
        "この説明により、ホップフィールドネットワークの **外積** を利用した学習プロセスや、ノイズの入ったパターンから記憶したパターンを再現する仕組みがより深く理解できるようになるはずです。"
      ],
      "metadata": {
        "id": "QD_pkzcEQj6D"
      }
    }
  ]
}